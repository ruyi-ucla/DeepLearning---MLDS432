{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/paramaggarwal/fashion-product-images-small?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 565M/565M [00:18<00:00, 31.8MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded at: /Users/wuwenfei/.cache/kagglehub/datasets/paramaggarwal/fashion-product-images-small/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Download Dataset using kagglehub\n",
    "path = kagglehub.dataset_download(\"paramaggarwal/fashion-product-images-small\")\n",
    "print(\"Dataset downloaded at:\", path)\n",
    "\n",
    "# Define dataset paths\n",
    "image_folder = os.path.join(path, \"images\")\n",
    "metadata_path = os.path.join(path, \"styles.csv\")\n",
    "\n",
    "# Step 2: Load metadata\n",
    "df = pd.read_csv(metadata_path, on_bad_lines='skip')\n",
    "\n",
    "# Filter dataset (only use images present in folder)\n",
    "df[\"image_path\"] = df[\"id\"].astype(str) + \".jpg\"\n",
    "df = df[df[\"image_path\"].isin(os.listdir(image_folder))]\n",
    "\n",
    "# Select a subset of classes for simplicity\n",
    "df = df[df['masterCategory'].isin(['Apparel', 'Footwear', 'Accessories'])]\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df[\"masterCategory\"].unique())}\n",
    "df[\"category_id\"] = df[\"masterCategory\"].map(label_map)\n",
    "\n",
    "# Split dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"category_id\"], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26807 validated image filenames belonging to 3 classes.\n",
      "Found 6701 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Image Preprocessing\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    train_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 198ms/step - accuracy: 0.4996 - loss: 1.0519 - val_accuracy: 0.5193 - val_loss: 1.0255\n",
      "Epoch 2/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 199ms/step - accuracy: 0.5100 - loss: 1.0332 - val_accuracy: 0.5193 - val_loss: 1.0226\n",
      "Epoch 3/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 176ms/step - accuracy: 0.5120 - loss: 1.0294 - val_accuracy: 0.5193 - val_loss: 1.0239\n",
      "Epoch 4/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 183ms/step - accuracy: 0.5081 - loss: 1.0315 - val_accuracy: 0.5193 - val_loss: 1.0236\n",
      "Epoch 5/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 184ms/step - accuracy: 0.5049 - loss: 1.0341 - val_accuracy: 0.5193 - val_loss: 1.0235\n",
      "Epoch 6/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 184ms/step - accuracy: 0.5099 - loss: 1.0310 - val_accuracy: 0.5193 - val_loss: 1.0233\n",
      "Epoch 7/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 183ms/step - accuracy: 0.5081 - loss: 1.0314 - val_accuracy: 0.5193 - val_loss: 1.0219\n",
      "Epoch 8/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 184ms/step - accuracy: 0.5075 - loss: 1.0324 - val_accuracy: 0.5193 - val_loss: 1.0231\n",
      "Epoch 9/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 182ms/step - accuracy: 0.5097 - loss: 1.0305 - val_accuracy: 0.5193 - val_loss: 1.0231\n",
      "Epoch 10/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 183ms/step - accuracy: 0.5047 - loss: 1.0347 - val_accuracy: 0.5193 - val_loss: 1.0230\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Definition (EfficientNet)\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(label_map), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8377 validated image filenames belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 150ms/step - accuracy: 0.5104 - loss: 1.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate Model\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"fashion_classifier.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
