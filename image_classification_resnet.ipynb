{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "875b42ec5baee5274279d8a7b7a72159f3a586de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 04:58:46.936166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 04:58:46.961123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-08 04:58:46.980809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-08 04:58:46.986755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 04:58:47.001479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-08 04:58:52.763561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "7c96d605282a65cebf83737bbf0a3386c5c3f19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: /nfs/home/mjc3869/.cache/kagglehub/datasets/paramaggarwal/fashion-product-images-small/versions/1\n"
     ]
    }
   ],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"paramaggarwal/fashion-product-images-small\")\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/nfs/home/mjc3869/.cache/kagglehub/datasets/paramaggarwal/fashion-product-images-small/versions/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "image_folder = os.path.join(dataset_path, \"images\")\n",
    "metadata_path = os.path.join(dataset_path, \"styles.csv\")\n",
    "\n",
    "# Step 2: Load metadata\n",
    "df = pd.read_csv(metadata_path, on_bad_lines='skip')\n",
    "\n",
    "# Filter dataset (only use images present in folder)\n",
    "df[\"image_path\"] = df[\"id\"].astype(str) + \".jpg\"\n",
    "df = df[df[\"image_path\"].isin(os.listdir(image_folder))]\n",
    "\n",
    "# Select a subset of classes for simplicity\n",
    "df = df[df['masterCategory'].isin(['Apparel', 'Footwear', 'Accessories'])]\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df[\"masterCategory\"].unique())}\n",
    "df[\"category_id\"] = df[\"masterCategory\"].map(label_map)\n",
    "\n",
    "# Split dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"category_id\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26807 validated image filenames belonging to 3 classes.\n",
      "Found 6701 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    train_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 05:00:11.040842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.042814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9461 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.044522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9461 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.046456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 2531 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.048201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 9461 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:88:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.049976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 9461 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:89:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.051675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 9461 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5\n",
      "2025-03-08 05:00:11.053354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 9461 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b2:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(label_map), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/mjc3869/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741410021.356413 3807047 service.cc:146] XLA service 0x7f9fac0029b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741410021.356472 3807047 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356480 3807047 service.cc:154]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356484 3807047 service.cc:154]   StreamExecutor device (2): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356488 3807047 service.cc:154]   StreamExecutor device (3): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356492 3807047 service.cc:154]   StreamExecutor device (4): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356496 3807047 service.cc:154]   StreamExecutor device (5): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356499 3807047 service.cc:154]   StreamExecutor device (6): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "I0000 00:00:1741410021.356503 3807047 service.cc:154]   StreamExecutor device (7): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-03-08 05:00:21.634310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-08 05:00:22.930140: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/838\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - accuracy: 0.3733 - loss: 1.1554   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741410025.651773 3807047 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 130ms/step - accuracy: 0.7904 - loss: 0.5100 - val_accuracy: 0.8966 - val_loss: 0.2506\n",
      "Epoch 2/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 136ms/step - accuracy: 0.9117 - loss: 0.2262 - val_accuracy: 0.8614 - val_loss: 0.3273\n",
      "Epoch 3/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 134ms/step - accuracy: 0.9271 - loss: 0.1929 - val_accuracy: 0.9346 - val_loss: 0.1741\n",
      "Epoch 4/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 120ms/step - accuracy: 0.9303 - loss: 0.1808 - val_accuracy: 0.9306 - val_loss: 0.1775\n",
      "Epoch 5/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 120ms/step - accuracy: 0.9362 - loss: 0.1733 - val_accuracy: 0.9419 - val_loss: 0.1647\n",
      "Epoch 6/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 123ms/step - accuracy: 0.9396 - loss: 0.1648 - val_accuracy: 0.9479 - val_loss: 0.1517\n",
      "Epoch 7/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 121ms/step - accuracy: 0.9411 - loss: 0.1586 - val_accuracy: 0.9460 - val_loss: 0.1559\n",
      "Epoch 8/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 123ms/step - accuracy: 0.9444 - loss: 0.1526 - val_accuracy: 0.9337 - val_loss: 0.1704\n",
      "Epoch 9/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 124ms/step - accuracy: 0.9445 - loss: 0.1564 - val_accuracy: 0.9346 - val_loss: 0.1635\n",
      "Epoch 10/10\n",
      "\u001b[1m838/838\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 121ms/step - accuracy: 0.9443 - loss: 0.1532 - val_accuracy: 0.9546 - val_loss: 0.1377\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8377 validated image filenames belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/mjc3869/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 114ms/step - accuracy: 0.9592 - loss: 0.1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, directory=image_folder, x_col=\"image_path\", y_col=\"masterCategory\",\n",
    "    target_size=image_size, batch_size=batch_size, class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"fashion_classifier_resnet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
